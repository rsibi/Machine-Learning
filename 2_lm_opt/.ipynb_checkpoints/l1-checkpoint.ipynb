{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "test_data = np.loadtxt('/home/sibi/acad/mach_learn_with_networks/assignment/2_lm_opt/bclass/bclass/bclass-test',delimiter='\\t')\n",
    "train_data = np.loadtxt('/home/sibi/acad/mach_learn_with_networks/assignment/2_lm_opt/bclass/bclass/bclass-train',delimiter='\\t')\n",
    "train_data = np.delete(train_data,2,1)\n",
    "\n",
    "X_train = train_data[:,1:]\n",
    "y_train = train_data[:,0]\n",
    "X_train.shape\n",
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.e**(-x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights(X_train, x, tau):\n",
    "    x = np.tile(x,(X_train.shape[0],1))\n",
    "    norm_squared = np.linalg.norm(X_train - x, axis = 1) ** 2\n",
    "    weights = np.exp(-norm_squared / (2*tau**2))\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_func(theta,x):\n",
    "    return float(1) / (1 + math.e**(-x.dot(theta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ZERO = 1e-5\n",
    "def lwlr(X_train, y_train, x, tau):  \n",
    "    m = X_train.shape[0]\n",
    "    n = X_train.shape[1]\n",
    "    lamb  = .0001\n",
    "    theta = np.zeros(n)\n",
    "    theta = theta.reshape(n,1)\n",
    "    grad = np.ones(n)\n",
    "    w = weights(X_train,x,0.1)\n",
    "\n",
    "    #print w\n",
    "    # wt: p.15, sum(_,axis=1) = sum the n cols of (Xi-xi)^2 into a single col of m vector\n",
    "    wt = np.exp( -np.sum((X_train - np.tile(x,(m,1)))**2, axis=1) / (2*tau))\n",
    "    while (np.linalg.norm(grad) > .000001):\n",
    "        \n",
    "        h = logistic_func(theta,X_train)\n",
    "#         print w.shape\n",
    "#         print y_train.shape\n",
    "#         print h.shape\n",
    "#         print (y_train - h).shape\n",
    "        grad = np.matmul(X_train.T, np.multiply(w, (y_train - np.array(h)))) - np.multiply(lamb, theta)\n",
    "        D = np.diag(np.multiply(np.multiply(w,h),(1-h)))  # m vector\n",
    "        print D.shape\n",
    "#         print X_train.shape\n",
    "        H = np.matmul(-X_train.T, np.matmul(D, X_train)) - np.multiply(lamb, theta)\n",
    "        #H = np.dot(-X_train.T, np.dot(D,X_train)) -lamb*theta  # n x n\n",
    "\n",
    "        #H = np.dot(-X_train.T , np.dot( (np.diag(w*h*(1-h))), X_train))  - (lamb*np.diag(n))\n",
    "        print \"Size : \"\n",
    "#         print H.size\n",
    "        theta = theta - np.dot(np.linalg.inv(H),grad)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200,)\n",
      "(200, 1)\n",
      "(200, 200)\n",
      "(200,)\n",
      "(200, 33)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (33,200) and (33,) not aligned: 200 (dim 1) != 33 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-377-bb67913f76bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlwlr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-376-6bb529a7594a>\u001b[0m in \u001b[0;36mlwlr\u001b[1;34m(X_train, y_train, x, tau)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlamb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m#H = np.dot(-X_train.T, np.dot(D,X_train)) -lamb*theta  # n x n\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (33,200) and (33,) not aligned: 200 (dim 1) != 33 (dim 0)"
     ]
    }
   ],
   "source": [
    "lwlr(X_train, y_train, x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
