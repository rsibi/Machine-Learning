{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_table('/home/sibi/acad/mach_learn_with_networks/assignment/2_lm_opt/bclass/bclass/bclass-train',delimiter='\\t',header=None)\n",
    "df_test = pd.read_table('/home/sibi/acad/mach_learn_with_networks/assignment/2_lm_opt/bclass/bclass/bclass-test',delimiter='\\t',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Converting -1 to 0\n",
    "df_train.head()\n",
    "df_train.loc[df_train[0] == -1,0] = 0\n",
    "df_test.loc[df_test[0] == -1,0] = 0\n",
    "df_train = df_train.drop(2, 1) #CAREFUL\n",
    "df_test = df_test.drop(2,1) #CAREFUL LABEL NAMES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Splitting as features and labels\n",
    "X_train = df_train.ix[:,1:]\n",
    "y_train = df_train[0]\n",
    "X_test = df_test.loc[:,1:]\n",
    "y_test = df_test.loc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locally weighted logistic regression\n",
    "\n",
    "## Gradient Descent Function\n",
    "\n",
    "The locally weighted logistic regression problem is to maximize\n",
    "$$ l(\\theta) = \\sum_{i=1}^{N} w^i \\{y^ilog\\:f_\\beta (x^i) + (1-y^i)\\:log(1 - log\\:f_\\beta(x^i)]\\} - \\lambda\\beta^T\\beta$$\n",
    "\n",
    "We first solve for the gradient and hessian using this function l. We can then conver this as an iterative procedure using the Newton-Raphson method.\n",
    "\n",
    "The gradient is given by  \n",
    "\n",
    "$\\quad \\nabla_\\theta\\:l(\\theta) = X^Tz - \\lambda\\theta$\n",
    "\n",
    "where z is the expresion \n",
    "\n",
    "$\\quad z_i = w^i \\:(y^i - h_\\theta(x^i)\\:)$\n",
    "\n",
    "and the Hessian is given by \n",
    "\n",
    "$\\quad H = X^TDX - \\lambda I$\n",
    "\n",
    "Where D is the diagonal matrix\n",
    "\n",
    "$\\quad D_{ii} = -w^i h_\\theta(x^i)(1-h_\\theta(x^i))$\n",
    "\n",
    "We now use these formulas to \n",
    "1. compute w i ’s for each development/test sample using the weight expression \n",
    "$w^i = exp(-\\frac{||x - x^i||}{2\\tau^2})$\n",
    "2. maximize l(β) to learn β, \n",
    "3. predict y based on f β (x) (y = 1 when f β (x) ≥ 0.5),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambda_value = 0.001\n",
    "\n",
    "def sigmoid(z): \n",
    "    return 1 / (1 + np.e**(-z)) \n",
    "\n",
    "def hypothesis(theta, x):\n",
    "    return sigmoid(np.dot(x, theta))\n",
    "\n",
    "def gaussian(point1, point2, tau):\n",
    "        return np.exp(- (np.linalg.norm(a-b)**2) / (2 * tau**2))\n",
    "\n",
    "def weights(data, new_point, tau):\n",
    "    assert (new_point.shape[0] == 1) #new point should be 1xn, where n is the number of features\n",
    "    new_point_repeat = np.repeat(new_point, data.shape[0], axis = 0) \n",
    "    norm_squared = np.linalg.norm(data - new_point_repeat, axis = 1) ** 2\n",
    "    weights = np.exp(-norm_squared / (2 * tau ** 2))\n",
    "    return weights.reshape(len(weights), 1)\n",
    "    \n",
    "def lw_logreg(x_train, y_train, x, tau):\n",
    "    x_train_aug = pd.concat([pd.Series(np.ones(len(x_train.index))), x_train], axis = 1)\n",
    "    x_aug = np.concatenate([np.asarray([[1]]), x], axis = 1)\n",
    "    \n",
    "    theta_length = x_train_aug.shape[1] \n",
    "    theta = np.zeros([theta_length, 1])\n",
    "    gradient = np.ones([33,1])\n",
    "\n",
    "    dist = 1\n",
    "    i = 0\n",
    "    while dist > 0.0001 and i < 100:\n",
    "        weights = getWeights(x_train_aug, x_aug, tau)\n",
    "#         print hypothesis(theta,x_train_aug).shape\n",
    "#         print weights.shape\n",
    "#         print y_train.shape\n",
    "        y_train = y_train.reshape(200,1)\n",
    "        z = weights * (y_train - hypothesis(theta, x_train_aug))\n",
    "        gradient = np.dot(x_train_aug.transpose(), z) -  lambda_value * theta\n",
    "\n",
    "        diags = -weights * hypothesis(theta, x_aug) * (1 - hypothesis(theta, x_aug))\n",
    "        D = np.diag(diags[:, 0])\n",
    "        H = np.dot(np.dot(x_train_aug.transpose(), D), x_train_aug) - lambda_value * np.eye(x_train_aug.shape[1]) #Hessian\n",
    "\n",
    "        theta_new = theta - np.dot(np.linalg.inv(H), gradient)\n",
    "\n",
    "        dist = np.linalg.norm(theta_new - theta)\n",
    "        theta = theta_new\n",
    "        i +=1\n",
    "\n",
    "    return theta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "0.665\n",
      "0.665\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "train_accs = []\n",
    "taus = [0.01, 0.05, 0.1, 1.0, 5.0]\n",
    "for tau in taus:\n",
    "    pred = []\n",
    "    for i in xrange(200):\n",
    "        x = X_train.iloc[[i]]\n",
    "        final_theta = lw_logreg(X_train, y_train, x, tau)\n",
    "        x_aug = np.concatenate([np.asarray([[1]]), x], axis = 1)\n",
    "\n",
    "        if hypothesis(final_theta,x_aug) > 0.5:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "       \n",
    "    train_acc = metrics.accuracy_score(y_train,pred)\n",
    "    print train_acc\n",
    "    train_accs.append(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.328947368421\n",
      "0.552631578947\n",
      "0.815789473684\n",
      "0.565789473684\n",
      "0.723684210526\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "test_accs = []\n",
    "taus = [0.01, 0.05, 0.1, 1.0, 5.0]\n",
    "for tau in taus:\n",
    "    pred = []\n",
    "    for i in xrange(X_test.shape[0]):\n",
    "        x = X_test.iloc[[i]]\n",
    "        final_theta = lw_logreg(X_train, y_train, x, tau)\n",
    "        x_aug = np.concatenate([np.asarray([[1]]), x], axis = 1)\n",
    "\n",
    "        if hypothesis(final_theta,x_aug) > 0.5:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "       \n",
    "    test_acc = metrics.accuracy_score(y_test,pred)\n",
    "    print test_acc\n",
    "    test_accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Plotting Error Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAH1CAYAAABcNjL6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlli/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5b93cf050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "width = 0.35\n",
    "ind = (0,0.5,1,1.5,2)\n",
    "\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax1.set_xlim(0,2.5)\n",
    "rects1 = ax1.bar(ind, train_accs, width, color='r',align ='center')\n",
    "# ax1.hist(taus,train_accs,label=\"Training Accuracy\",)\n",
    "# ax1.bar( test_accs,label=\"Training Accuracy\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.set_xticklabels(('0.01', '0.05', '0.1', '1', '5'))\n",
    "\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
